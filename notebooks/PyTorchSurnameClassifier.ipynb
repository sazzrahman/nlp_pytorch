{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Version descrepancies on this one\n",
    "from tqdm import tqdm_notebook as notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from helper.vocabulary_builder import Vocabulary, SurnameVectorizer, SurnameDataset, SurnameClassifier\n",
    "# from helper.vocabulary_builder import ModelUtils\n",
    "\n",
    "from helper.custom_utils import ModelUtils\n",
    "from helper.custom_dataset import SurnameDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "surname_csv = \"../data/surnames_with_splits.csv\",\n",
    "vectorizer_file = \"vectorizer.json\",\n",
    "model_state_file = \"model.pth\",\n",
    "save_dir = \"../data/model_state\",\n",
    "hidden_dim = 300,\n",
    "seed = 1337,\n",
    "num_epochs = 100,\n",
    "early_stopping_criteria=5,\n",
    "learning_rate = 0.001,\n",
    "batch_size=64,\n",
    "cuda = False,\n",
    "reload_from_files=False,\n",
    "expand_filepaths_to_save_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t../data/model_state/vectorizer.json\n",
      "\t../data/model_state/model.pth\n"
     ]
    }
   ],
   "source": [
    "# Just creating filepaths..not the actual files\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelUtils.set_seed_everywhere(args.seed,args.cuda)\n",
    "ModelUtils.handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fresh!\n"
     ]
    }
   ],
   "source": [
    "# Model Initializations\n",
    "if args.reload_from_files:\n",
    "    print(\"Reloading !\")\n",
    "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
    "                                                              args.vectorizer_file)\n",
    "    \n",
    "else:\n",
    "    print(\"Creating fresh!\")\n",
    "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "    \n",
    "vectorizer = dataset.get_vectorizer()\n",
    "classifier = SurnameClassifier(input_dim = len(vectorizer.surname_vocab),\n",
    "                              hidden_dim = args.hidden_dim,\n",
    "                              output_dim = len(vectorizer.nationality_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "\n",
    "# Whyn am I feeding class weights to loss function ??\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(),lr = args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min',factor=0.5,patience=1)\n",
    "\n",
    "train_state = ModelUtils.make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4112c70725460b8076d8b23d8f9312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='training routine', style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c408cc38ec471cb107e1a8721ee4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='split=train', max=120, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f1ed56708846e7a2f49849ee48baec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='split=validation', max=25, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_bar = notebook(desc = 'training routine',\n",
    "                         total = args.num_epochs,\n",
    "                         position = 0\n",
    "                         )\n",
    "dataset.set_split('train')\n",
    "train_bar = notebook(desc = 'split=train',\n",
    "                         total = dataset.get_num_batches(args.batch_size),\n",
    "                         position=1,\n",
    "                         leave=True)\n",
    "\n",
    "dataset.set_split('validation')\n",
    "val_bar = notebook(desc = 'split=validation',\n",
    "                         total = dataset.get_num_batches(args.batch_size),\n",
    "                         position=1,\n",
    "                         leave=True)\n",
    "\n",
    "\n",
    "try:    \n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        # for the first iteration train_state gets default values\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        # dataset mode : training\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = ModelUtils.generate_batches(dataset,batch_size=args.batch_size,device=args.device)\n",
    "        \n",
    "        #running loss and acc will reset to zero\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # predicting value just by passing value to classifier. \n",
    "            y_pred = classifier(batch_dict['x_surname'])\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "            loss_t = loss.item()\n",
    "            \n",
    "            ## why running loss needs to be divided by batch index?\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # compute running accuracy\n",
    "            acc_t = ModelUtils.compute_accuracy(y_pred,batch_dict['y_nationality'])\n",
    "            \n",
    "            # why divide by batch index?\n",
    "            running_acc += (acc_t - running_acc)/(batch_index + 1)\n",
    "            \n",
    "            # update the running loss and running accuracy for training bar. \n",
    "            train_bar.set_postfix(loss=running_loss,acc=running_acc, epoch = epoch_index)\n",
    "            train_bar.update()\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "        \n",
    "        # dataset mode validation\n",
    "        # cleaning up before validation routine\n",
    "        batch_generator = ModelUtils.generate_batches(dataset,batch_size=args.batch_size,device=args.device)\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        classifier.eval()\n",
    "        dataset.set_split(\"validation\")\n",
    "        \n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator): \n",
    "            # predicting value just by passing value to classifier. \n",
    "            y_pred = classifier(batch_dict['x_surname'])\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "            \n",
    "            acc_t = ModelUtils.compute_accuracy(y_pred,batch_dict['y_nationality'])\n",
    "            running_acc += (acc_t - running_acc)/(batch_index + 1)\n",
    "            \n",
    "            val_bar.set_postfix(loss=running_loss,acc=running_acc,epoch = epoch_index)\n",
    "            val_bar.update()\n",
    "            \n",
    "            \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "        \n",
    "        \n",
    "        train_state = ModelUtils.update_train_state(args=args,model=classifier,train_state=train_state)\n",
    "        \n",
    "        # has to do with learning rate adjustment\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "        \n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting Loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_val': 100000000.0,\n",
       " 'learing_rate': 0.001,\n",
       " 'epoch_index': 0,\n",
       " 'train_loss': [],\n",
       " 'train_acc': [],\n",
       " 'val_loss': [],\n",
       " 'val_acc': [],\n",
       " 'test_loss': 2.2086644697189333,\n",
       " 'test_acc': 59.6875,\n",
       " 'model_filename': '../data/model_state/model.pth'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re initiate the classifier\n",
    "# classifier = SurnameClassifier(input_dim = len(vectorizer.surname_vocab),\n",
    "#                               hidden_dim = args.hidden_dim,\n",
    "#                               output_dim = len(vectorizer.nationality_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must use map_location parameter for deserializing to cpu.\n",
    "# Load pretrained weights to classifier.\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'],map_location=torch.device(args.device) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each batch has to be predicted and computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = ModelUtils.generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # this is the pretrained classifier aka the model.\n",
    "    y_pred =  classifier(batch_dict['x_surname'])\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = ModelUtils.compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2086644697189333, 59.6875)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state['test_loss'], train_state['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tensors must go to device\n",
    "\n",
    "def predict_nationality(surname, classifier, vectorizer, device=args.device):\n",
    "    \"\"\"Predict the nationality from a new surname\n",
    "    \n",
    "    Args:\n",
    "        surname (str): the surname to classifier\n",
    "        classifier (SurnameClassifer): an instance of the classifier\n",
    "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        a dictionary with the most likely nationality and its probability\n",
    "    \"\"\"\n",
    "    vectorized_surname = vectorizer.vectorize(surname)\n",
    "    vectorized_surname = torch.tensor(vectorized_surname).view(1, -1)\n",
    "    # must send the new tensor to device\n",
    "    vectorized_surname = vectorized_surname.to(device)\n",
    "    result = classifier(vectorized_surname, apply_softmax=True)\n",
    "\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    index = indices.item()\n",
    "\n",
    "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return {'nationality': predicted_nationality, 'probability': probability_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a surname to classify:  rhaman\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rhaman -> German (p=0.51)\n"
     ]
    }
   ],
   "source": [
    "new_surname = input(\"Enter a surname to classify: \")\n",
    "classifier = classifier.to(args.device)\n",
    "prediction = predict_nationality(new_surname, classifier, vectorizer)\n",
    "print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                    prediction['nationality'],\n",
    "                                    prediction['probability']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topk_nationality(name, classifier, vectorizer, k=5, device=args.device):\n",
    "    vectorized_name = vectorizer.vectorize(name)\n",
    "    vectorized_name = torch.tensor(vectorized_name).view(1, -1)\n",
    "    vectorized_name = vectorized_name.to(device)\n",
    "    prediction_vector = classifier(vectorized_name, apply_softmax=True)\n",
    "    probability_values, indices = torch.topk(prediction_vector, k=k)\n",
    "    \n",
    "    # returned size is 1,k\n",
    "    # cpu conversion is necessary because tensor object cannot directly interact with numpy\n",
    "    probability_values = probability_values.detach().cpu().numpy()[0]\n",
    "    indices = indices.detach().cpu().numpy()[0]\n",
    "    \n",
    "    results = []\n",
    "    for prob_value, index in zip(probability_values, indices):\n",
    "        nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "        results.append({'nationality': nationality, \n",
    "                        'probability': prob_value})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a surname to classify:  rahman\n",
      "How many of the top predictions to see?  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 8 predictions:\n",
      "===================\n",
      "rahman -> German (p=0.51)\n",
      "rahman -> English (p=0.29)\n",
      "rahman -> Irish (p=0.08)\n",
      "rahman -> Czech (p=0.04)\n",
      "rahman -> French (p=0.03)\n",
      "rahman -> Scottish (p=0.03)\n",
      "rahman -> Russian (p=0.01)\n",
      "rahman -> Dutch (p=0.01)\n"
     ]
    }
   ],
   "source": [
    "new_surname = input(\"Enter a surname to classify: \")\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "k = int(input(\"How many of the top predictions to see? \"))\n",
    "if k > len(vectorizer.nationality_vocab):\n",
    "    print(\"Sorry! That's more than the # of nationalities we have.. defaulting you to max size :)\")\n",
    "    k = len(vectorizer.nationality_vocab)\n",
    "    \n",
    "predictions = predict_topk_nationality(new_surname, classifier, vectorizer, k=k)\n",
    "\n",
    "print(\"Top {} predictions:\".format(k))\n",
    "print(\"===================\")\n",
    "for prediction in predictions:\n",
    "    print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                        prediction['nationality'],\n",
    "                                        prediction['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of MLP\n",
    "\n",
    "+ Why bojac and jacob is classified as same Nationality and with identical probability\n",
    "+ Rahman --> Irish, rahman --> German"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
