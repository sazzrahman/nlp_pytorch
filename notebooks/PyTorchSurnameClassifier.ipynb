{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Version descrepancies on this one\n",
    "from tqdm import tqdm_notebook as notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helper.mlp_classifier import SurnameClassifier\n",
    "from helper.custom_utils import ModelUtils\n",
    "from helper.mlp_dataset import SurnameDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "surname_csv = \"../data/surnames_with_splits.csv\",\n",
    "vectorizer_file = \"vectorizer.json\",\n",
    "model_state_file = \"model.pth\",\n",
    "save_dir = \"../data/model_state\",\n",
    "hidden_dim = 300,\n",
    "seed = 1337,\n",
    "num_epochs = 100,\n",
    "early_stopping_criteria=5,\n",
    "learning_rate = 0.001,\n",
    "batch_size=64,\n",
    "cuda = False,\n",
    "reload_from_files=False,\n",
    "expand_filepaths_to_save_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t../data/model_state/vectorizer.json\n",
      "\t../data/model_state/model.pth\n"
     ]
    }
   ],
   "source": [
    "# Just creating filepaths..not the actual files\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.vectorizer_file))\n",
    "    print(\"\\t{}\".format(args.model_state_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "    \n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelUtils.set_seed_everywhere(args.seed,args.cuda)\n",
    "ModelUtils.handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fresh!\n"
     ]
    }
   ],
   "source": [
    "# Model Initializations\n",
    "if args.reload_from_files:\n",
    "    print(\"Reloading !\")\n",
    "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
    "                                                              args.vectorizer_file)\n",
    "    \n",
    "else:\n",
    "    print(\"Creating fresh!\")\n",
    "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "    \n",
    "vectorizer = dataset.get_vectorizer()\n",
    "classifier = SurnameClassifier(input_dim = len(vectorizer.surname_vocab),\n",
    "                              hidden_dim = args.hidden_dim,\n",
    "                              output_dim = len(vectorizer.nationality_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "\n",
    "# Whyn am I feeding class weights to loss function ??\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(),lr = args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min',factor=0.5,patience=1)\n",
    "\n",
    "train_state = ModelUtils.make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sazz/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9afdba3e80d40339b108e6c0beedb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sazz/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88de47696c249eeb2ec825847bd2c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=120.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sazz/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0006dc06998846b8bb8487a545efb4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=validation', max=25.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_bar = notebook(desc = 'training routine',\n",
    "                         total = args.num_epochs,\n",
    "                         position = 0\n",
    "                         )\n",
    "dataset.set_split('train')\n",
    "train_bar = notebook(desc = 'split=train',\n",
    "                         total = dataset.get_num_batches(args.batch_size),\n",
    "                         position=1,\n",
    "                         leave=True)\n",
    "\n",
    "dataset.set_split('validation')\n",
    "val_bar = notebook(desc = 'split=validation',\n",
    "                         total = dataset.get_num_batches(args.batch_size),\n",
    "                         position=1,\n",
    "                         leave=True)\n",
    "\n",
    "\n",
    "try:    \n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        # for the first iteration train_state gets default values\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        # dataset mode : training\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = ModelUtils.generate_batches(dataset,batch_size=args.batch_size,device=args.device)\n",
    "        \n",
    "        #running loss and acc will reset to zero\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # predicting value just by passing value to classifier. \n",
    "            y_pred = classifier(batch_dict['x_surname'])\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "            loss_t = loss.item()\n",
    "            \n",
    "            ## why running loss needs to be divided by batch index?\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # compute running accuracy\n",
    "            acc_t = ModelUtils.compute_accuracy(y_pred,batch_dict['y_nationality'])\n",
    "            \n",
    "            # why divide by batch index?\n",
    "            running_acc += (acc_t - running_acc)/(batch_index + 1)\n",
    "            \n",
    "            # update the running loss and running accuracy for training bar. \n",
    "            train_bar.set_postfix(loss=running_loss,acc=running_acc, epoch = epoch_index)\n",
    "            train_bar.update()\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "        \n",
    "        # dataset mode validation\n",
    "        # cleaning up before validation routine\n",
    "        batch_generator = ModelUtils.generate_batches(dataset,batch_size=args.batch_size,device=args.device)\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        classifier.eval()\n",
    "        dataset.set_split(\"validation\")\n",
    "        \n",
    "        \n",
    "        for batch_index, batch_dict in enumerate(batch_generator): \n",
    "            # predicting value just by passing value to classifier. \n",
    "            y_pred = classifier(batch_dict['x_surname'])\n",
    "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "            \n",
    "            acc_t = ModelUtils.compute_accuracy(y_pred,batch_dict['y_nationality'])\n",
    "            running_acc += (acc_t - running_acc)/(batch_index + 1)\n",
    "            \n",
    "            val_bar.set_postfix(loss=running_loss,acc=running_acc,epoch = epoch_index)\n",
    "            val_bar.update()\n",
    "            \n",
    "            \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "        \n",
    "        \n",
    "        train_state = ModelUtils.update_train_state(args=args,model=classifier,train_state=train_state)\n",
    "        \n",
    "        # has to do with learning rate adjustment\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "        \n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting Loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_val': 100000000.0,\n",
       " 'learing_rate': 0.001,\n",
       " 'epoch_index': 99,\n",
       " 'train_loss': [2.725182360410691,\n",
       "  2.2382738063732783,\n",
       "  1.9208319107691445,\n",
       "  1.7678079863389333,\n",
       "  1.667573764920235,\n",
       "  1.6138932079076773,\n",
       "  1.554712516069412,\n",
       "  1.5177146603663765,\n",
       "  1.4833445241053902,\n",
       "  1.432928857704004,\n",
       "  1.4171951919794086,\n",
       "  1.399843825896581,\n",
       "  1.3862092037995655,\n",
       "  1.3778129185239474,\n",
       "  1.3715325380365053,\n",
       "  1.368757975101471,\n",
       "  1.3635253235697742,\n",
       "  1.3546929424007734,\n",
       "  1.3466340313355125,\n",
       "  1.3362543731927874,\n",
       "  1.3321321263909338,\n",
       "  1.3288516332705818,\n",
       "  1.3341496845086418,\n",
       "  1.3368919665614758,\n",
       "  1.3383843337496117,\n",
       "  1.328145331144333,\n",
       "  1.3340359235803287,\n",
       "  1.3321303715308517,\n",
       "  1.3289497936765349,\n",
       "  1.335713585714499,\n",
       "  1.3306596636772154,\n",
       "  1.3326024522384012,\n",
       "  1.3248027041554447,\n",
       "  1.3259046648939454,\n",
       "  1.3312854493657753,\n",
       "  1.323997878531615,\n",
       "  1.3190348515907926,\n",
       "  1.331933689117432,\n",
       "  1.3217384482423464,\n",
       "  1.3271986285845436,\n",
       "  1.3235594585537918,\n",
       "  1.3310736015439035,\n",
       "  1.3266947199900956,\n",
       "  1.3262858053048456,\n",
       "  1.3276707639296852,\n",
       "  1.3293900360663733,\n",
       "  1.3283907458186142,\n",
       "  1.324157306551933,\n",
       "  1.3327145641048754,\n",
       "  1.3277833233277003,\n",
       "  1.3280940026044836,\n",
       "  1.3284629518787063,\n",
       "  1.3211241419116657,\n",
       "  1.3357766787211105,\n",
       "  1.3196387822429345,\n",
       "  1.3278005162874855,\n",
       "  1.3309262489279117,\n",
       "  1.3315289864937465,\n",
       "  1.3269115413228665,\n",
       "  1.3271307145555806,\n",
       "  1.333552022278309,\n",
       "  1.3229732885956753,\n",
       "  1.3267210607727369,\n",
       "  1.3334005961815518,\n",
       "  1.3267050817608832,\n",
       "  1.3292021488149965,\n",
       "  1.3318691268563272,\n",
       "  1.329769925773144,\n",
       "  1.3259035001198447,\n",
       "  1.333616949121157,\n",
       "  1.324229578177134,\n",
       "  1.3366413181026773,\n",
       "  1.3252590919534366,\n",
       "  1.3258651167154314,\n",
       "  1.3310853168368337,\n",
       "  1.3359801928202315,\n",
       "  1.3292026738325757,\n",
       "  1.3273684725165373,\n",
       "  1.3289570882916448,\n",
       "  1.3335795422395065,\n",
       "  1.3269603083531065,\n",
       "  1.3292847037315372,\n",
       "  1.3267770787080126,\n",
       "  1.3281890541315078,\n",
       "  1.3343977039059,\n",
       "  1.327172020574411,\n",
       "  1.3196693564454705,\n",
       "  1.330076450606187,\n",
       "  1.32742269039154,\n",
       "  1.3292194043596588,\n",
       "  1.3351434300343197,\n",
       "  1.3256298035383216,\n",
       "  1.3333902413646384,\n",
       "  1.3232678224643073,\n",
       "  1.328399155537287,\n",
       "  1.3297466675440466,\n",
       "  1.3304627095659576,\n",
       "  1.3220751106739042,\n",
       "  1.3223903606335319,\n",
       "  1.324950248003006],\n",
       " 'train_acc': [29.947916666666675,\n",
       "  40.40364583333331,\n",
       "  41.69270833333333,\n",
       "  43.20312499999999,\n",
       "  45.07812500000001,\n",
       "  44.63541666666666,\n",
       "  45.9375,\n",
       "  46.58854166666667,\n",
       "  46.861979166666664,\n",
       "  48.90625000000001,\n",
       "  48.242187500000014,\n",
       "  48.97135416666666,\n",
       "  49.062500000000014,\n",
       "  49.04947916666666,\n",
       "  49.54427083333333,\n",
       "  49.453125,\n",
       "  49.42708333333333,\n",
       "  49.947916666666636,\n",
       "  49.986979166666686,\n",
       "  49.908854166666664,\n",
       "  49.85677083333332,\n",
       "  50.16927083333334,\n",
       "  50.07812500000001,\n",
       "  50.15625000000001,\n",
       "  50.299479166666664,\n",
       "  50.247395833333336,\n",
       "  50.22135416666667,\n",
       "  50.208333333333336,\n",
       "  50.20833333333332,\n",
       "  50.221354166666686,\n",
       "  50.23437500000001,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.247395833333314,\n",
       "  50.24739583333331,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.24739583333333,\n",
       "  50.24739583333333,\n",
       "  50.24739583333334,\n",
       "  50.24739583333332,\n",
       "  50.24739583333333,\n",
       "  50.24739583333335,\n",
       "  50.247395833333336,\n",
       "  50.24739583333334,\n",
       "  50.24739583333332,\n",
       "  50.24739583333333,\n",
       "  50.24739583333334,\n",
       "  50.247395833333336,\n",
       "  50.247395833333336,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.24739583333336,\n",
       "  50.24739583333331,\n",
       "  50.247395833333336,\n",
       "  50.24739583333335,\n",
       "  50.24739583333334,\n",
       "  50.247395833333336,\n",
       "  50.2473958333333,\n",
       "  50.24739583333333,\n",
       "  50.247395833333336,\n",
       "  50.24739583333334,\n",
       "  50.24739583333333,\n",
       "  50.24739583333332,\n",
       "  50.24739583333333,\n",
       "  50.24739583333332,\n",
       "  50.247395833333336,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.24739583333332,\n",
       "  50.247395833333314,\n",
       "  50.24739583333334,\n",
       "  50.24739583333332,\n",
       "  50.24739583333333,\n",
       "  50.24739583333336,\n",
       "  50.24739583333333,\n",
       "  50.24739583333333,\n",
       "  50.24739583333333,\n",
       "  50.24739583333332,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.247395833333336,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.24739583333333,\n",
       "  50.24739583333332,\n",
       "  50.24739583333331,\n",
       "  50.24739583333334,\n",
       "  50.24739583333334,\n",
       "  50.24739583333331,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.247395833333336,\n",
       "  50.24739583333333,\n",
       "  50.247395833333314,\n",
       "  50.24739583333334,\n",
       "  50.24739583333331,\n",
       "  50.247395833333336,\n",
       "  50.24739583333332,\n",
       "  50.24739583333335],\n",
       " 'val_loss': [2.511166820526123,\n",
       "  2.1273179626464844,\n",
       "  1.9852529096603395,\n",
       "  1.915640916824341,\n",
       "  1.886676745414734,\n",
       "  1.8723733568191532,\n",
       "  1.846429076194763,\n",
       "  1.8552949476242064,\n",
       "  1.8503810358047486,\n",
       "  1.8611569595336914,\n",
       "  1.8580116081237787,\n",
       "  1.8295848560333252,\n",
       "  1.827623710632324,\n",
       "  1.8070671987533569,\n",
       "  1.77079514503479,\n",
       "  1.7826197814941407,\n",
       "  1.792642273902893,\n",
       "  1.822131905555725,\n",
       "  1.7785343408584595,\n",
       "  1.7991646003723145,\n",
       "  1.831806035041809,\n",
       "  1.8364994525909424,\n",
       "  1.7985719490051268,\n",
       "  1.8252724599838257,\n",
       "  1.8258858537673952,\n",
       "  1.788096218109131,\n",
       "  1.8343270683288577,\n",
       "  1.8458889722824097,\n",
       "  1.8168678665161133,\n",
       "  1.8427054834365844,\n",
       "  1.8411100912094114,\n",
       "  1.8260949277877807,\n",
       "  1.8280077981948855,\n",
       "  1.8235909271240234,\n",
       "  1.8376727056503295,\n",
       "  1.8052763700485228,\n",
       "  1.8135198545455935,\n",
       "  1.8155624437332152,\n",
       "  1.8221220541000367,\n",
       "  1.7813445425033572,\n",
       "  1.7973220729827881,\n",
       "  1.7971120691299434,\n",
       "  1.8287613916397094,\n",
       "  1.8417344713211061,\n",
       "  1.814484324455261,\n",
       "  1.8160353040695187,\n",
       "  1.8244016456604004,\n",
       "  1.828478078842163,\n",
       "  1.8059030246734618,\n",
       "  1.8310066986083986,\n",
       "  1.8024606752395629,\n",
       "  1.8008383560180663,\n",
       "  1.8167153978347776,\n",
       "  1.792637939453125,\n",
       "  1.8134014701843262,\n",
       "  1.7761579513549803,\n",
       "  1.847453999519348,\n",
       "  1.7957517337799072,\n",
       "  1.783830919265747,\n",
       "  1.8065600681304936,\n",
       "  1.7963194704055787,\n",
       "  1.7831976461410524,\n",
       "  1.8094923543930053,\n",
       "  1.8204144525527957,\n",
       "  1.8022057151794433,\n",
       "  1.8471637058258055,\n",
       "  1.820500087738037,\n",
       "  1.8342990446090701,\n",
       "  1.823994426727295,\n",
       "  1.8321484327316284,\n",
       "  1.8211537885665892,\n",
       "  1.8099417066574097,\n",
       "  1.8450753974914547,\n",
       "  1.8256244993209838,\n",
       "  1.7931206178665162,\n",
       "  1.8321594572067257,\n",
       "  1.8295606327056886,\n",
       "  1.807917504310608,\n",
       "  1.7886918687820437,\n",
       "  1.7979722452163696,\n",
       "  1.830130844116211,\n",
       "  1.8239023303985598,\n",
       "  1.8033394050598142,\n",
       "  1.7876639223098756,\n",
       "  1.8216805505752562,\n",
       "  1.7918509912490845,\n",
       "  1.81426628112793,\n",
       "  1.8375917053222655,\n",
       "  1.8307731246948242,\n",
       "  1.8302450656890867,\n",
       "  1.8402950525283814,\n",
       "  1.838664093017578,\n",
       "  1.8114697122573853,\n",
       "  1.8139263582229614,\n",
       "  1.8242639493942259,\n",
       "  1.8187383460998536,\n",
       "  1.8157977056503296,\n",
       "  1.790359447002411,\n",
       "  1.8242395401000975,\n",
       "  1.8185405921936038],\n",
       " 'val_acc': [40.93749999999999,\n",
       "  40.50000000000001,\n",
       "  41.875,\n",
       "  44.625,\n",
       "  39.0625,\n",
       "  44.62500000000001,\n",
       "  41.06250000000001,\n",
       "  42.1875,\n",
       "  46.43749999999999,\n",
       "  43.50000000000001,\n",
       "  44.1875,\n",
       "  43.81250000000001,\n",
       "  44.62500000000001,\n",
       "  45.8125,\n",
       "  44.375,\n",
       "  44.249999999999986,\n",
       "  45.625,\n",
       "  44.99999999999999,\n",
       "  44.12500000000001,\n",
       "  44.62500000000001,\n",
       "  44.875,\n",
       "  44.8125,\n",
       "  45.0,\n",
       "  44.99999999999999,\n",
       "  44.99999999999999,\n",
       "  45.0625,\n",
       "  44.75000000000001,\n",
       "  44.93750000000001,\n",
       "  45.0,\n",
       "  45.00000000000001,\n",
       "  44.99999999999999,\n",
       "  44.93750000000001,\n",
       "  45.0,\n",
       "  44.8125,\n",
       "  45.1875,\n",
       "  45.0,\n",
       "  45.375,\n",
       "  45.1875,\n",
       "  44.875000000000014,\n",
       "  45.25000000000001,\n",
       "  44.81250000000001,\n",
       "  45.0,\n",
       "  44.999999999999986,\n",
       "  45.0625,\n",
       "  44.625,\n",
       "  45.0625,\n",
       "  44.99999999999999,\n",
       "  45.12499999999999,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  45.1875,\n",
       "  45.25,\n",
       "  45.1875,\n",
       "  44.81250000000001,\n",
       "  45.06250000000001,\n",
       "  45.0625,\n",
       "  45.18749999999999,\n",
       "  44.87500000000001,\n",
       "  44.75,\n",
       "  45.25000000000001,\n",
       "  45.0,\n",
       "  45.24999999999999,\n",
       "  44.93749999999999,\n",
       "  45.437499999999986,\n",
       "  45.25000000000001,\n",
       "  45.0625,\n",
       "  44.9375,\n",
       "  45.1875,\n",
       "  44.937500000000014,\n",
       "  44.625,\n",
       "  44.9375,\n",
       "  44.87499999999999,\n",
       "  44.75000000000001,\n",
       "  44.812499999999986,\n",
       "  44.9375,\n",
       "  44.87499999999999,\n",
       "  45.06249999999999,\n",
       "  44.875,\n",
       "  45.0,\n",
       "  45.125,\n",
       "  45.5,\n",
       "  45.0625,\n",
       "  45.1875,\n",
       "  44.87500000000001,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  44.99999999999999,\n",
       "  45.3125,\n",
       "  45.12499999999999,\n",
       "  44.81249999999999,\n",
       "  44.75000000000001,\n",
       "  44.8125,\n",
       "  45.0625,\n",
       "  44.9375,\n",
       "  44.93749999999999,\n",
       "  44.87499999999999,\n",
       "  45.06250000000001,\n",
       "  44.5625,\n",
       "  44.9375,\n",
       "  44.750000000000014],\n",
       " 'test_loss': -1,\n",
       " 'test_acc': -1,\n",
       " 'model_filename': '../data/model_state/model.pth'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re initiate the classifier\n",
    "# classifier = SurnameClassifier(input_dim = len(vectorizer.surname_vocab),\n",
    "#                               hidden_dim = args.hidden_dim,\n",
    "#                               output_dim = len(vectorizer.nationality_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must use map_location parameter for deserializing to cpu.\n",
    "# Load pretrained weights to classifier.\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename'],map_location=torch.device(args.device) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each batch has to be predicted and computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = ModelUtils.generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # this is the pretrained classifier aka the model.\n",
    "    y_pred =  classifier(batch_dict['x_surname'])\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = ModelUtils.compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8359884548187257, 44.93749999999999)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_state['test_loss'], train_state['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All tensors must go to device\n",
    "\n",
    "def predict_nationality(surname, classifier, vectorizer, device=args.device):\n",
    "    \"\"\"Predict the nationality from a new surname\n",
    "    \n",
    "    Args:\n",
    "        surname (str): the surname to classifier\n",
    "        classifier (SurnameClassifer): an instance of the classifier\n",
    "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        a dictionary with the most likely nationality and its probability\n",
    "    \"\"\"\n",
    "    vectorized_surname = vectorizer.vectorize(surname)\n",
    "    vectorized_surname = torch.tensor(vectorized_surname).view(1, -1)\n",
    "    # must send the new tensor to device\n",
    "    vectorized_surname = vectorized_surname.to(device)\n",
    "    result = classifier(vectorized_surname, apply_softmax=True)\n",
    "\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    index = indices.item()\n",
    "\n",
    "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return {'nationality': predicted_nationality, 'probability': probability_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c9ab773b5317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_surname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a surname to classify: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_nationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_surname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nationality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_surname = input(\"Enter a surname to classify: \")\n",
    "classifier = classifier.to(args.device)\n",
    "prediction = predict_nationality(new_surname, classifier, vectorizer)\n",
    "print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                    prediction['nationality'],\n",
    "                                    prediction['probability']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topk_nationality(name, classifier, vectorizer, k=5, device=args.device):\n",
    "    vectorized_name = vectorizer.vectorize(name)\n",
    "    vectorized_name = torch.tensor(vectorized_name).view(1, -1)\n",
    "    vectorized_name = vectorized_name.to(device)\n",
    "    prediction_vector = classifier(vectorized_name, apply_softmax=True)\n",
    "    probability_values, indices = torch.topk(prediction_vector, k=k)\n",
    "    \n",
    "    # returned size is 1,k\n",
    "    # cpu conversion is necessary because tensor object cannot directly interact with numpy\n",
    "    probability_values = probability_values.detach().cpu().numpy()[0]\n",
    "    indices = indices.detach().cpu().numpy()[0]\n",
    "    \n",
    "    results = []\n",
    "    for prob_value, index in zip(probability_values, indices):\n",
    "        nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "        results.append({'nationality': nationality, \n",
    "                        'probability': prob_value})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_surname = input(\"Enter a surname to classify: \")\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "k = int(input(\"How many of the top predictions to see? \"))\n",
    "if k > len(vectorizer.nationality_vocab):\n",
    "    print(\"Sorry! That's more than the # of nationalities we have.. defaulting you to max size :)\")\n",
    "    k = len(vectorizer.nationality_vocab)\n",
    "    \n",
    "predictions = predict_topk_nationality(new_surname, classifier, vectorizer, k=k)\n",
    "\n",
    "print(\"Top {} predictions:\".format(k))\n",
    "print(\"===================\")\n",
    "for prediction in predictions:\n",
    "    print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                        prediction['nationality'],\n",
    "                                        prediction['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of MLP\n",
    "\n",
    "+ Why bojac and jacob is classified as same Nationality and with identical probability\n",
    "+ Rahman --> Irish, rahman --> German"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
